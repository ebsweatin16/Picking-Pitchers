---
title: "Picking Pitchers Data Analyis"
author: "Eric Breton"
date: "August 15th, 2019"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r, echo=FALSE}
knitr::opts_chunk$set(error = TRUE)
```



```{r Establish Libraries}

install.packages("XML")
install.packages("RCurl")
install.packages("RVest")
install.packages("reshape2")
install.packages("tldyr")
install.packages("data.table")
install.packages("stringi")
install.packages("sqldf")
install.packages("dplyr")
install.packages('corrplot')
install.packages("ggplot2")
install.packages("factoextra")
install.packages("cowplot")
install.packages("cluster")
install.packages("NbClust")
install.packages("Lahman")
install.packages("data.table")
install.packages("DAAG")
install.packages("caret")
install.packages(knn)

library(NbClust)
library(cluster)
library(cowplot)
library(factoextra)
library(corrplot)
library(ggplot2)
library(XML)
library(class)
library(rvest)
library(dplyr)
library(reshape2)
library(data.table)
library(stringi)
library(sqldf)
library (lattice)
library(ggplot2)
library(tidyverse)
library(ggpubr)
# library(rlist)
# library(lahman)
library(kableExtra)
library(DAAG)
library(caret)
```

```{r  Pull in Data}
setwd("C:/Users/ebret/Desktop/Practicum Part 2")
dataset<-fread("Analysis_Dataset.csv")
#head(dataset)
```

```{r  Correlation}
#I did some initial testing and  Josh Collmente came out as his own cluster, so I am taking him out of the equation
dataset<-dataset%>%filter(pitcher!="collmjo01")
cor_data<-dataset[,-(0:2)]
#had some integer columns so converted all to numeric

cor_data %<>% mutate_if(is.integer,as.numeric)

##str(cor_data)

#far too many values
#corrplot(cor(cor_data), type = "upper", method = "color", tl.cex = .5)
```

```{r  Four Seamers}

fs_cor_Data<-sqldf('select
fs_whiffs,	fs_bips,	
fs_gbs,	fs_lds,	fs_fbs,	fs_pus,	fs_hrs,	fs_perc_thrown,	fs_velocity,	fs_h_mvmt,	
fs_v_mvmt,	fs_h_rel,	fs_v_rel,	coors_ERA,		career_C_ERA,	Total_Whiffs,	Variance_ERA
from cor_data')

corrplot(cor(fs_cor_Data), type = "upper", method = "color", tl.cex = .7, title = "Four Seamers",mar=c(0,0,5,0))


```
Inducing more whiffs with the fourseamer improves performance at Coors Field
```{r  Change Ups}

cu_cor_Data<-sqldf('select
cu_whiffs,	cu_bips,	
cu_gbs,	cu_lds,	cu_fbs,	cu_pus,	cu_hrs,	cu_perc_thrown,	cu_velocity,	cu_h_mvmt,	
cu_v_mvmt,	cu_h_rel,	cu_v_rel,	coors_ERA,		career_C_ERA,		Variance_ERA
from cor_data')

corrplot(cor(cu_cor_Data), type = "upper", method = "color", tl.cex = .7, title = "Change Ups",mar=c(0,0,5,0))


```
A pitcher's movement and release on his change up seem to be much more beneficial away from Coors as they have little or no impact on success at Coors.
```{r  Curve ball}

c_cor_Data<-sqldf('select
c_whiffs,	c_bips,	
c_gbs,	c_lds,	c_fbs,	c_pus,	c_hrs,	c_perc_thrown,	c_velocity,	c_h_mvmt,	
c_v_mvmt,	c_h_rel,	c_v_rel,	coors_ERA,		career_C_ERA,	Variance_ERA
from cor_data')

corrplot(cor(c_cor_Data), type = "upper", method = "color", tl.cex = .7, title = "Curve Balls",mar=c(0,0,5,0))

```
Outcomes or pitch descriptions of curve balls have little correlation with success at Coors other than contributing to slightly higher ERA numbers

```{r  Cutters}

cut_cor_Data<-sqldf('select
cut_whiffs,	cut_bips,	
cut_gbs,	cut_lds,	cut_fbs,	cut_pus,	cut_hrs,	cut_perc_thrown,	cut_velocity,	cut_h_mvmt,	
cut_v_mvmt,	cut_h_rel,	cut_v_rel,	coors_ERA,		career_C_ERA,		Variance_ERA
from cor_data')

corrplot(cor(cut_cor_Data), type = "upper", method = "color", tl.cex = .7, title = "Cutters",mar=c(0,0,5,0))
```
Cutters no matter how you thrown them tend to slight increase a pitchers ERA at Coors.
```{r  Sinkers}

sink_cor_Data<-sqldf('select
sink_whiffs,	sink_bips,	
sink_gbs,	sink_lds,	sink_fbs,	sink_pus,	sink_hrs,	sink_perc_thrown,	sink_velocity,	sink_h_mvmt,	
sink_v_mvmt,	sink_h_rel,	sink_v_rel,	coors_ERA,		career_c_ERA,		Variance_ERA
from cor_data')

corrplot(cor(sink_cor_Data), type = "upper", method = "color", tl.cex = .7, title = "Sinkers",mar=c(0,0,5,0))
```
Hard thrown sinkers with good vertical movement tend to translate better to career numbers than those at Coors.
```{r  Sliders}

slld_cor_Data<-sqldf('select
	slld_whiffs,	slld_bips,	
slld_gbs,	slld_lds,	slld_fbs,	slld_pus,	slld_hrs,	slld_perc_thrown,	slld_velocity,	slld_h_mvmt,	
slld_v_mvmt,	slld_h_rel,	slld_v_rel,	coors_ERA,		career_c_ERA,		Variance_ERA
from cor_data')

corrplot(cor(slld_cor_Data), type = "upper", method = "color", tl.cex = .7, title = "Sliders",mar=c(0,0,5,0))
```
Sliders with plus movement both vertically and horizontally lead to more success at Coors.
```{r  Slow Curves}

sc_cor_Data<-sqldf('select
	sc_whiffs,	sc_bips,	
sc_gbs,	sc_lds,	sc_fbs,	sc_pus,	sc_hrs,	sc_perc_thrown,	sc_velocity,	sc_h_mvmt,	
sc_v_mvmt,	sc_h_rel,	sc_v_rel,	coors_ERA,		career_c_ERA,		Variance_ERA
from cor_data')

corrplot(cor(sc_cor_Data), type = "upper", method = "color", tl.cex = .9, title = "Slow Curves",mar=c(0,0,5,0))
```
Splitters no matter how you throw them as long as your throw them prove to be good pitches at Coors.
```{r  Splitters}

split_cor_Data<-sqldf('select
split_count,	split_balls,	split_strikes,	split_swing,	split_fouls,	split_whiffs,	split_bips,	
split_gbs,	split_lds,	split_fbs,	split_pus,	split_hrs,	split_perc_thrown,	split_velocity,	split_h_mvmt,	
split_v_mvmt,	split_h_rel,	split_v_rel,	coors_ERA,		career_c_ERA,		Variance_ERA
from cor_data')

corrplot(cor(split_cor_Data), type = "upper", method = "color", tl.cex = .7, title = "Splitters",mar=c(0,0,5,0))
```
Pitchers throwing splitters at Coors have better success than their overall career numbers.
```{r  Pitch Types}

Pitch_types<-sqldf('
select
fs_perc_thrown fourseamer,	cu_perc_thrown changeup,	c_perc_thrown curveball	,cut_perc_thrown cutter,slld_perc_thrown slider,	sink_perc_thrown sinker ,sc_perc_thrown slowcurve,
	split_perc_thrown splitter	,coors_ERA,		career_c_ERA career_era,		Variance_ERA
from cor_data')

corrplot(cor(Pitch_types), type = "upper", method = "color", tl.cex = .9, title = "Pitch_types",mar=c(0,0,5,0))
```

```{r  Pitch Outcomes}

Pitch_types<-sqldf('
select
Total_Whiffs Whiffs,	Total_fbs Flyballs,	Total_gbs Groundballs,	Total_hrs Homers ,	Total_bips "Balls in Play",	Variance_ERA,coors_ERA Coors_ERA,		career_c_ERA Career_ERA,Variance_ERA Variance_ERA
from cor_data')

corrplot(cor(Pitch_types), type = "upper", method = "color", tl.cex = .9, title = "Pitch_Outcomes",mar=c(0,0,5,0))
```

```{r  Pitching Career}

career<-sqldf('
select
coors_ERA,	career_C_ERA Career_ERA,career_C_Hper9 Career_Hitsper9,		career_C_BBper9 Career_walksper9,	career_C_Kper9 Career_Ksper9,	career_C_HRper9 Career_HRsper9

from cor_data')

corrplot(cor(career), type = "upper", method = "color", tl.cex = .7, title = "Career",mar=c(0,0,5,0))
```




```{r  Variance Summaries}

summary(dataset$Variance_BBper9)
summary(dataset$Variance_Kper9)
summary(dataset$Variance_HRper9)
summary(dataset$Variance_ERA)
summary(dataset$Variance_Hper9)
```

```{r scale the my day data Version 2}
# #head(cor_data)
cor_data<-cor_data[-156]
cd<-cor_data
#head(cd)
cluster_data_1<-sqldf('select 
fs_whiffs,fs_bips,fs_gbs,fs_fbs,fs_hrs,fs_perc_thrown,fs_velocity,
cu_whiffs,cu_bips,cu_gbs,cu_fbs,cu_hrs,cu_perc_thrown,
c_whiffs,c_bips,c_gbs,c_lds,c_fbs,c_hrs,c_perc_thrown,
cut_whiffs,cut_bips,cut_gbs,cut_fbs,cut_hrs,cut_perc_thrown,
sink_swing,sink_whiffs,sink_bips,sink_gbs,sink_fbs,sink_hrs,sink_perc_thrown,
slld_whiffs,slld_bips,slld_gbs,slld_fbs,slld_hrs,slld_perc_thrown,
sc_whiffs,sc_bips,sc_gbs,sc_fbs,sc_hrs,sc_perc_thrown,
split_whiffs,split_bips,split_gbs,split_fbs,split_hrs,
split_perc_thrown from cd')
#head(cluster_data_1)
cd_scaled <- scale(cluster_data_1)
#Add back my row names
rownames(cd_scaled) <- dataset$pitcher
#view(cd_scaled)
##view(cd_scaled)


```


I will run clustering analysis for a large number of clusters. Next I will graph the different clusters and perform a bit of an eyeball test how the groups look.
```{r Clustering}


#Setting my seed so my results will be reproducable
set.seed=42
#in this step I create a way in which I will be able to run multiple numbers of clusters at the same time and the check them all togther. This makes things much more efficient for me.
kmean_calc <- function(df, ...){
  kmeans(df, scaled = ..., nstart = 25)
}
km2 <- kmean_calc(cd_scaled, 2)
km3 <- kmean_calc(cd_scaled, 3)
km4 <- kmeans(cd_scaled, 4)
km5 <- kmeans(cd_scaled, 5)
km6 <- kmeans(cd_scaled, 6)
km7 <- kmeans(cd_scaled, 7)
km8 <- kmeans(cd_scaled, 8)
km9 <- kmeans(cd_scaled, 9)
km10 <- kmeans(cd_scaled, 10)
km11 <- kmeans(cd_scaled, 11)

#Plotting my viusals on the plot grid will give me a visual indication of how my clusters look.
p1 <- fviz_cluster(km2, data = cd_scaled,geom = "point", frame.type = "ellipse") + theme_minimal() + ggtitle("k = 2") 
p2 <- fviz_cluster(km3, data = cd_scaled,geom = "point", frame.type = "ellipse") + theme_minimal() + ggtitle("k = 3")
p3 <- fviz_cluster(km4, data = cd_scaled,geom = "point", frame.type = "ellipse") + theme_minimal() + ggtitle("k = 4")
p4 <- fviz_cluster(km5, data = cd_scaled,geom = "point", frame.type = "ellipse") + theme_minimal() + ggtitle("k = 5")
p5 <- fviz_cluster(km6, data = cd_scaled,geom = "point", frame.type = "ellipse") + theme_minimal() + ggtitle("k = 6")
p6 <- fviz_cluster(km7, data = cd_scaled,geom = "point", frame.type = "ellipse") + theme_minimal() + ggtitle("k = 7")
plot_grid(p1, p2, p3, p4, p5, p6, labels = c("B", "B", "B", "B", "B", "B"))

```

Determine the optimal number of clusters based on the elbow method of testing.

```{r Elbow Method: Determining Number of Clusters}

#function to compute total within-cluster sum of squares
fviz_nbclust(cd_scaled, kmeans, method = "wss", k.max = 10) + theme_minimal() + ggtitle("The Elbow Method Both")


```


Define the optimal number of clusters by using the Silhouette method.

```{r Silhouette Method: Determining Number of Clusters}
fviz_nbclust(cd_scaled, kmeans, method = "silhouette", k.max = 24) + theme_minimal() + ggtitle("The Silhouette Plot")


```

Following my Silhouette and Elbow Method evaluation for optimal number of clusters they both agree that the optimal number of clusters for my analysis is 6.
```{r}
#Set colors for my graph
p3<-c('#33006F','#C4CED4','#000000','#1A79E4')
#Run the acutal K meand clustering
pc <- kmeans(cd_scaled, 6, nstart = 25)
#
pc
#Examine and aggregate my different variables based on the clusters which were created.
as.data.frame(cd_scaled) %>% mutate(Cluster = pc$cluster) %>% group_by(Cluster) %>% summarise_all("mean") %>% kable() %>% kable_styling()

fviz_cluster(pc, data = cd_scaled,pointsize = .5, labelsize = 7) + theme_minimal() + ggtitle("Pitcher Profiles") 

dataset<-dataset %>%mutate(Cluster=pc$cluster)
#save off my results from my clustering analysis
#write.csv(dataset,"Clustered_Dataset6.csv")
pc$totss
#3825
pc$withinss
#355.6239 218.3505 716.4912  41.6021 514.0563 591.4067
pc$tot.withinss
#2437.531
pc$betweenss
#1387.469
pc$size
#7  8 15  3 18 25
```







Beging to Perform Regression Analysis:


```{r Start Prepping and looking at the data for Regression}
reg_data<-cor_data
#outlier throwing off graphs and dat
 reg_data<-filter(reg_data, Variance_ERA < 14)

#Create the metric which I will be using to predict my
reg_data<-reg_data %>%mutate(cb_pitches=as.numeric((reg_data$fs_perc_thrown+reg_data$slld_perc_thrown+reg_data$sink_perc_thrown+reg_data$split_perc_thrown)))
                             
#str(reg_data$cb_pitches)                            


```


```{r Check Assumptions}
 # Histogram with density instead of count on y-axis
ggplot(reg_data, aes(x=cb_pitches)) + geom_histogram(aes(y=..density..),
binwidth=5, colour="black", fill="white") + geom_density(alpha=.5, fill="#FF6666")
hist(reg_data$cb_pitches, density=20, breaks=20, prob=TRUE, 
     xlab="x-variable", 
     main="normal curve over histogram")
curve(dnorm(x, mean=mean(reg_data$cb_pitches), sd=sqrt(var(reg_data$cb_pitches))), 
      col="darkblue", lwd=2, add=TRUE, yaxt="n")
m<-lm(reg_data$Variance_ERA~reg_data$cb_pitches)
plot(m)
nrow(reg_data)
#removed row
reg_data<-slice(reg_data,-74,-59)
nrow(reg_data)
````



```{r Begin Linear Regression}

#Begin by runing simple linear regression
attach(reg_data)
lm.fit=lm(reg_data$Variance_ERA~reg_data$cb_pitches)
#coeffieincets
lm.fit
#Get information
summary(lm.fit)
confint(lm.fit)
plot(cb_pitches,Variance_ERA)
abline(lm.fit)
```



```{r using}
attach(reg_data)

cor(Variance_ERA, cb_pitches)
#Cor value 0f -.27 is fairly low but era is a rate so it still has value
lMod <- lm(Variance_ERA ~ cb_pitches, data=reg_data)
summary(lMod)

set.seed(100)  # setting seed to reproduce results of random sampling
trainingRowIndex <- sample(1:nrow(reg_data), 0.8*nrow(reg_data))  # row indices for training data
trainingData <- reg_data[trainingRowIndex, ]  # model training data
testData  <- reg_data[-trainingRowIndex, ]   # test data

lmMod <- lm(Variance_ERA ~ cb_pitches, data=trainingData)  # build the model
ERAPred <- predict(lmMod, testData)  # predict distance
summary (lmMod)


actuals_preds <- data.frame(cbind(actuals=testData$Variance_ERA, predicteds=ERAPred))  # make actuals_predicteds dataframe.

correlation_accuracy <- cor(actuals_preds)

correlation_accuracy# 82.7%
#view(actuals_preds)

```






```{r Prepping data for Knn Classification}
# Create a Data Set with just my Total Runs
#using my medin value to set my classification
dataset<-fread("Analysis_Dataset.csv")
```

```{r  Correlation}
#I did some initial testing and  Josh Collmente came out as his own cluster, so I am taking him out of the equation
dataset<-dataset%>%filter(pitcher!="collmjo01")
cor_data<-dataset[,-(0:2)]
#had some integer columns so converted all to numeric

cor_data %<>% mutate_if(is.integer,as.numeric)
#use mean as my classifier to say pitcher's performance will have a worst or better variance than the avg
var_era<-mean(cor_data$Variance_ERA)

knn_data<-cor_data[-156]
###head(cor_data)
cd<-sqldf('select 
fs_whiffs,fs_bips,fs_gbs,fs_fbs,fs_hrs,fs_perc_thrown,fs_velocity,
cu_whiffs,cu_bips,cu_gbs,cu_fbs,cu_hrs,cu_perc_thrown,
c_whiffs,c_bips,c_gbs,c_lds,c_fbs,c_hrs,c_perc_thrown,
cut_whiffs,cut_bips,cut_gbs,cut_fbs,cut_hrs,cut_perc_thrown,
sink_swing,sink_whiffs,sink_bips,sink_gbs,sink_fbs,sink_hrs,sink_perc_thrown,
slld_whiffs,slld_bips,slld_gbs,slld_fbs,slld_hrs,slld_perc_thrown,
sc_whiffs,sc_bips,sc_gbs,sc_fbs,sc_hrs,sc_perc_thrown,
split_whiffs,split_bips,split_gbs,split_fbs,split_hrs,
split_perc_thrown from cor_data')

cd_scaled <- scale(cd)
#Add back my row names
rownames(cd_scaled) <- dataset$pitcher
#view(cd_scaled)


```


```{r Knn Classification}
#Set seed so that my process is repatable
set.seed(100)

dt<-data.table(cd_scaled)
dt$Variance_ERA<-ifelse(cor_data$Variance_ERA>var_era,1,0)
dt$Variance_ERA=as.factor(dt$Variance_ERA)
# Seperate my classifier from my variables
targs <- dt[, Variance_ERA]
#view(targs)
feats <- dt[, -'Variance_ERA']
#80% of my sample size
train.idxs <- createDataPartition(targs, p = 0.8)$Resample1
##Vew(train.idxs)
# create features and targets
tr.feats <- feats[train.idxs]
#Vew(tr.feats)
tr.targs <- targs[train.idxs]
##Vew(tr.targs)
te.feats <- feats[-train.idxs]
te.targs <- targs[-train.idxs]
```


This function will tell me the average number of times my prediction of Y is accurate.
```{r acc_func}
# calculate accuracy
accuracy <- function(y.true, y.pred) {
  return(mean(y.true == y.pred))
}
```


```{r knn_class}
#Creating two vectors for my testing and training scores to
te.scores <- c()
tr.scores <- c()

#Generating a list of whole numbers that I can loop through for analyzing the best number of nearest numbers
n.neighbors <- seq(1, 50)
nrow(tr.feats)
nrow(tr.targs)
nrow(te.feats)
#Running a loop for all k values between 1 through 50 which will give me the data necessary to determine the optimal number of k for my model
for (k in n.neighbors) {
#Training the data on my training features (pitch desc/outcome) classifying the Variance on my test set
te.preds <- knn(train = tr.feats, cl = tr.targs, test = te.feats, k = k)
#Training the data on my training features (pitch desc/outcome) classifying the Variance on my training set
  tr.preds <- knn(train = tr.feats, cl = tr.targs, test = tr.feats, k = k)
#Returns the cores for both knn analysis from my accuracy function which is taking in the predicted value and the actual value and spitting out the average number of times they equalled each other
  te.scores <- c(te.scores, accuracy(te.preds, te.targs))
  tr.scores <- c(tr.scores, accuracy(tr.preds, tr.targs))
}
par(mfrow=c(1, 2))
plot(n.neighbors, te.scores)
lines(n.neighbors, te.scores)
plot(n.neighbors, tr.scores)
lines(n.neighbors, tr.scores)
max.acc.idx <- which.max(te.scores)
print(paste('Testing Scores best accuracy of',
            round(te.scores[max.acc.idx], 2),
            'at k=',
            n.neighbors[max.acc.idx],
            sep = ' '))

print(paste('Training Scores best accuracy of',
            round(tr.scores[max.acc.idx], 2),
            'at k=',
            n.neighbors[max.acc.idx],
            sep = ' '))
```


I will do some cross validation on the training set. The results of this will change multiple times due to the randomness of how the data will get split. My prior results showed a value of 3 for K at 79% accuracy.

The first portion of this I will use 5 folds in my cross validation which will divide my dat into 5 observation groups. One of these folds will be held out and use as the validating fold. From this the mean squared error is calculated. The process is than repeated 5 times for each of my observation groups with each group being held out once, this will give me an estimate of the test error.

```{r caret_knn}


trControl <- trainControl(method  = "cv",
                          number  = 5)
fit <- train(Variance_ERA ~ .,
             method     = 'knn',
             tuneGrid   = expand.grid(k = 1:50),
             trControl  = trControl,
             preProcess = c("center", "scale"),
             metric     = "Accuracy",
             data       = dt[train.idxs])

ks <- fit$results$k
acc <- fit$results$Accuracy
par(mfrow = c(1, 1))
plot(ks, acc, main = 'cross-validation accuracy')
lines(ks, acc)
max.acc.idx <- which.max(fit$results$Accuracy)
print(paste('best accuracy of',
            round(acc[max.acc.idx], 2),
            'at k=', ks[max.acc.idx],
            sep = ' '))


```
Following the cross validation (ran 5 times) on the training dataset I got an average k value of 3 with an accuracy of 63%.
Running cross validation on the whole dataset.  
```{r full_cv}
trControl <- trainControl(method  = "cv",
                          number  = 5)

fit <- train(Variance_ERA ~ .,
             method     = 'knn',
             tuneGrid   = expand.grid(k = 1:50),
             trControl  = trControl,
             preProcess = c("center", "scale"),
             metric     = "Accuracy",
             data       = dt)

ks <- fit$results$k
acc <- fit$results$Accuracy
par(mfrow = c(1, 1))
plot(ks, acc, main = 'cross-validation accuracy')
lines(ks, acc)
max.acc.idx <- which.max(fit$results$Accuracy)

print(paste('best accuracy of',
            round(acc[max.acc.idx], 2),
            'at k=', ks[max.acc.idx],
            sep = ' '))
```

In running on the entire data set I returned a value of k of 3 with an accuracy of 73%

```{r conf_matrix}
preds <- predict(fit, dt[, -'Variance_ERA'])
confusionMatrix(preds, dt[, Variance_ERA])

```

```{r Prepping to test data for all}
# Create a Data Set with just my Total Runs
#using my medin value to set my classification
dataset_all<-fread("Analysis_Dataset_all.csv")
```

```{r  Correlation}


cor_data_all<-dataset_all[,-(0:3)]
#had some integer columns so converted all to numeric
cor_data_all %<>% mutate_if(is.character,as.numeric)
#use mean as my classifier to say pitcher's performance will have a worst or better variance than the avg
var_era<-mean(cor_data_all$Variance_ERA)
#var_era--ERA Value from all pitcher
knn_data_all<-cor_data_all[-156]
###head(cor_data)
cd_all<-sqldf('select 
fs_whiffs,fs_bips,fs_gbs,fs_fb fs_fbs,fs_hrs,fs_perc_thrown,fs_velocity,
cu_whiffs,cu_bips,cu_gbs,cu_fb cu_fbs,cu_hrs,cu_perc_thrown,
c_whiffs,c_bips,c_gbs,c_lds,c_fb c_fbs,c_hrs,c_perc_thrown,
cut_whiffs,cut_bips,cut_gbs,cut_fb cut_fbs,cut_hrs,cut_perc_thrown,
sink_swing,sink_whiffs,sink_bips,sink_gbs,sink_fb sink_fbs,sink_hrs,sink_perc_thrown,
slld_whiffs,slld_bips,slld_gbs,slld_fb slld_fbs,slld_hrs,slld_perc_thrown,
sc_whiffs,sc_bips,sc_gbs,sc_fb sc_fbs,sc_hrs,sc_perc_thrown,
split_whiffs,split_bips,split_gbs,split_fb split_fbs,split_hrs,
split_perc_thrown from cor_data_all')

cd_scaled_all <- scale(cd_all)
View(cd_scaled_all)
#Add back my row names
rownames(cd_scaled_all) <- dataset_all$pitcher
#use model to test against all pitchers regardless of number of starts
new <- knn(train = dt[, -'Variance_ERA'], cl = dt$Variance_ERA, test = cd_scaled_all, k = 3)
dataset_all<-dataset_all[,-(0:2)]
dataset_all<-dataset_all %>%mutate(prediction=new)
test<-sqldf('
      select count(*),
      case when Variance_ERA >4.045155 then 1 else 0 end prediction_value,
      prediction from dataset_all group by prediction,case when Variance_ERA >4.045155 then 1 else 0 end ,
      prediction')
View(test)


```



























